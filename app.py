import streamlit as st
import os
import time
from rag_system import RAGChatbot
import logging

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Chatbot IMDB",
    page_icon="üé¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personalizado
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #ff6b6b, #4ecdc4);
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .chat-container {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
    }
    .user-message {
        background-color: #007bff;
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        text-align: right;
    }
    .bot-message {
        background-color: #28a745;
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
    }
    .source-box {
        background-color: #e9ecef;
        padding: 0.5rem;
        border-radius: 5px;
        margin: 0.2rem 0;
        font-size: 0.9em;
    }
    .stats-box {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #ffc107;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_resource
def initialize_chatbot():
    """Inicializa el chatbot optimizado para RTX 4070 (solo una vez)"""
    chatbot = RAGChatbot()
    # Usar configuraci√≥n optimizada desde .env
    max_movies = int(os.getenv("MAX_MOVIES", "25000"))
    success = chatbot.initialize(max_movies=max_movies, use_cache=True)
    return chatbot, success

def main():
    # Header principal
    st.markdown("""
    <div class="main-header">
        <h1 style="color: white; text-align: center; margin: 0;">
            üé¨ Chatbot IMDB - Asistente de Pel√≠culas
        </h1>
        <p style="color: white; text-align: center; margin: 0;">
            Preg√∫ntame cualquier cosa sobre pel√≠culas, series y la base de datos de IMDB
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è Configuraci√≥n del Sistema")
        
        # Informaci√≥n del hardware
        st.subheader("ÔøΩÔ∏è Hardware Detectado")
        try:
            import torch
            if torch.cuda.is_available():
                gpu_name = torch.cuda.get_device_name(0)
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
                st.success(f"üöÄ GPU: {gpu_name}")
                st.info(f"üíæ VRAM: {gpu_memory:.1f} GB")
            else:
                st.warning("‚ö†Ô∏è GPU no detectada, usando CPU")
        except:
            st.warning("‚ö†Ô∏è No se pudo detectar hardware")
        
        st.divider()
        
        # Configuraci√≥n del modelo
        st.subheader("ü§ñ Configuraci√≥n del Modelo")
        temperature = st.slider("Temperatura", 0.1, 1.0, 0.7, 0.1)
        max_length = st.slider("Longitud m√°xima de respuesta", 200, 1200, 800, 50)
        top_k = st.slider("N√∫mero de documentos a recuperar", 3, 15, 8)
        
        # Actualizar variables de entorno
        os.environ["TEMPERATURE"] = str(temperature)
        os.environ["MAX_RESPONSE_LENGTH"] = str(max_length)
        os.environ["TOP_K"] = str(top_k)
        
        st.divider()
        
        # Informaci√≥n del sistema
        st.subheader("üìä Estado del Sistema")
        if st.button("üîç Mostrar Informaci√≥n GPU"):
            try:
                import torch
                if torch.cuda.is_available():
                    memory_allocated = torch.cuda.memory_allocated(0) / 1e9
                    memory_cached = torch.cuda.memory_reserved(0) / 1e9
                    st.metric("VRAM Usada", f"{memory_allocated:.1f} GB")
                    st.metric("VRAM Reservada", f"{memory_cached:.1f} GB")
                else:
                    st.info("GPU no disponible")
            except:
                st.error("Error obteniendo informaci√≥n de GPU")
        
        # Bot√≥n para reinicializar
        if st.button("üîÑ Reinicializar Sistema"):
            st.cache_resource.clear()
            st.rerun()
    
    # Inicializar chatbot
    with st.spinner("Inicializando sistema RAG con OpenHermes-2.5-Mistral-7B... Esto puede tomar unos minutos la primera vez."):
        chatbot, success = initialize_chatbot()
    
    if not success:
        st.error("‚ùå Error inicializando el sistema. Por favor, verifica tu configuraci√≥n.")
        return
    
    # Mostrar estad√≠sticas del sistema
    stats = chatbot.get_stats()
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        status = "‚úÖ Optimizado" if stats["sistema_inicializado"] else "‚ùå Error"
        st.metric("Estado del Sistema", status)
    
    with col2:
        docs_count = f"{stats['documentos_en_base']:,}"
        st.metric("Documentos en Base", docs_count)
    
    with col3:
        modelo = "OpenHermes-2.5-Mistral-7B"
        if stats["modelo_activo"]:
            modelo_completo = stats["modelo_activo"]
            if "OpenHermes" in modelo_completo:
                modelo = "OpenHermes-2.5-Mistral-7B"
            else:
                modelo = modelo_completo.split("/")[-1]
        st.metric("Modelo", modelo)
    
    with col4:
        kb_status = "‚úÖ OpenHermes Optimizada" if stats["base_conocimiento_lista"] else "‚ùå Error"
        st.metric("Base de Conocimiento", kb_status)
    
    st.divider()
    
    # Interfaz principal de chat
    st.header("üí¨ Chat con el Asistente")
    
    # Inicializar historial de chat en session state
    if "messages" not in st.session_state:
        st.session_state.messages = []
        st.session_state.messages.append({
            "role": "assistant",
            "content": "¬°Hola! Soy tu asistente de IMDB potenciado por OpenHermes-2.5-Mistral-7B. Puedo ayudarte con informaci√≥n detallada sobre pel√≠culas, series, actores, directores y cualquier tema relacionado con el cine. ¬øEn qu√© puedo ayudarte hoy?"
        })
    
    # Mostrar historial de chat
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # Mostrar fuentes si las hay
            if message["role"] == "assistant" and "sources" in message:
                if message["sources"]:
                    with st.expander("üìö Fuentes consultadas"):
                        for i, source in enumerate(message["sources"], 1):
                            st.markdown(f"**Fuente {i}:**")
                            st.markdown(f"```\n{source}\n```")
    
    # Input del usuario
    if prompt := st.chat_input("Escribe tu pregunta sobre pel√≠culas o IMDB..."):
        # A√±adir mensaje del usuario al historial
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # Mostrar mensaje del usuario
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # Generar respuesta del asistente
        with st.chat_message("assistant"):
            with st.spinner("Buscando informaci√≥n y generando respuesta..."):
                # Consultar al chatbot
                result = chatbot.query(prompt)
                
                # Mostrar respuesta
                st.markdown(result["response"])
                
                # Mostrar fuentes si las hay
                if result["sources"]:
                    with st.expander("üìö Fuentes consultadas"):
                        for i, source in enumerate(result["sources"], 1):
                            st.markdown(f"**Fuente {i}:**")
                            st.markdown(f"```\n{source}\n```")
                
                # A√±adir respuesta al historial
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": result["response"],
                    "sources": result["sources"]
                })
    
    # Secci√≥n de herramientas adicionales
    st.divider()
    st.header("üîß Herramientas Adicionales")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üîç B√∫squeda de Pel√≠culas")
        search_query = st.text_input("Buscar pel√≠cula por t√≠tulo:")
        
        if search_query:
            with st.spinner("Buscando pel√≠culas..."):
                movies = chatbot.search_movies(search_query, limit=5)
            
            if movies:
                for movie in movies:
                    with st.expander(f"üé¨ {movie.get('primaryTitle', 'T√≠tulo desconocido')} ({movie.get('startYear', 'N/A')})"):
                        st.write(f"**T√≠tulo original:** {movie.get('originalTitle', 'N/A')}")
                        st.write(f"**A√±o:** {movie.get('startYear', 'N/A')}")
                        st.write(f"**G√©neros:** {movie.get('genres', 'N/A')}")
                        st.write(f"**Duraci√≥n:** {movie.get('runtimeMinutes', 'N/A')} minutos")
                        st.write(f"**ID IMDB:** {movie.get('tconst', 'N/A')}")
            else:
                st.warning("No se encontraron pel√≠culas con ese t√≠tulo.")
    
    with col2:
        st.subheader("üìä Informaci√≥n del Sistema")
        with st.container():
            st.markdown("""
            <div class="stats-box">
                <h4>ü§ñ Sistema OpenHermes-2.5-Mistral-7B:</h4>
                <ul>
                    <li><strong>Modelo:</strong> OpenHermes-2.5-Mistral-7B (conversacional avanzado)</li>
                    <li><strong>Embeddings:</strong> MPNet-v2 (mejor comprensi√≥n sem√°ntica)</li>
                    <li><strong>Base de datos:</strong> 25,000+ pel√≠culas de IMDB</li>
                    <li><strong>GPU:</strong> Cuantizaci√≥n 4-bit optimizada para RTX 4070</li>
                    <li><strong>Respuestas:</strong> Hasta 1200 tokens conversacionales</li>
                    <li><strong>Retrieval:</strong> 8 documentos por consulta</li>
                </ul>
                <h4>üí° Consejos de uso:</h4>
                <ul>
                    <li>Pregunta sobre pel√≠culas espec√≠ficas, actores o directores</li>
                    <li>Puedes preguntar sobre g√©neros, a√±os o ratings</li>
                    <li>El sistema funciona mejor con preguntas espec√≠ficas</li>
                    <li>Usa la b√∫squeda de pel√≠culas para encontrar t√≠tulos exactos</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)
    
    # Footer
    st.divider()
    st.markdown("""
    <div style="text-align: center; color: #666; font-size: 0.9em;">
        üé¨ Chatbot IMDB - Potenciado por OpenHermes-2.5-Mistral-7B<br>
        üöÄ OpenHermes + MPNet-v2 | 25K+ pel√≠culas | Cuantizaci√≥n 4-bit<br>
        ‚ö° Powered by Hugging Face, FAISS y Streamlit
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
