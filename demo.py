#!/usr/bin/env python3
"""
Script de demostraciÃ³n del Chatbot IMDB
"""

def demo_queries():
    """Consultas de demostraciÃ³n"""
    return [
        "Â¿CuÃ¡les son las mejores pelÃ­culas de Christopher Nolan?",
        "InformaciÃ³n sobre la pelÃ­cula Inception",
        "Â¿QuÃ© pelÃ­culas de acciÃ³n tienen el mejor rating?",
        "Actores principales de The Dark Knight",
        "PelÃ­culas de ciencia ficciÃ³n de los aÃ±os 80",
        "Â¿CuÃ¡l es la pelÃ­cula con mejor rating de 2020?",
        "Directores mÃ¡s famosos de Hollywood",
        "PelÃ­culas de terror mÃ¡s populares",
        "Â¿QuÃ© son los Premios Oscar?",
        "InformaciÃ³n sobre actores de Marvel"
    ]

def run_demo():
    """Ejecutar demostraciÃ³n del sistema optimizado para RTX 4070"""
    print("ğŸ¬ Demo del Chatbot IMDB - RTX 4070 Optimizado")
    print("=" * 60)
    
    try:
        from rag_system import RAGChatbot
        
        print("ğŸš€ Inicializando sistema RAG optimizado...")
        chatbot = RAGChatbot()
        
        # Inicializar con configuraciÃ³n optimizada
        success = chatbot.initialize(max_movies=5000, use_cache=True)  # 5K para demo rÃ¡pida
        
        if not success:
            print("âŒ Error inicializando el sistema")
            return
        
        print("âœ… Sistema inicializado con optimizaciones RTX 4070!")
        print("\nğŸ“Š EstadÃ­sticas del sistema:")
        stats = chatbot.get_stats()
        for key, value in stats.items():
            print(f"  {key}: {value}")
        
        # Mostrar informaciÃ³n de GPU si estÃ¡ disponible
        try:
            import torch
            if torch.cuda.is_available():
                print(f"\nğŸ–¥ï¸ GPU: {torch.cuda.get_device_name(0)}")
                print(f"ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
            else:
                print("\nâš ï¸ GPU no detectada, usando CPU")
        except:
            print("\nâš ï¸ No se pudo verificar GPU")
        
        print("\nğŸ¯ Ejecutando consultas de demostraciÃ³n...")
        print("-" * 60)
        
        queries = demo_queries()
        
        for i, query in enumerate(queries[:3], 1):  # Solo las primeras 3 para la demo
            print(f"\nğŸ’¬ Consulta {i}: {query}")
            print("ğŸ¤” Procesando con modelo optimizado...")
            
            result = chatbot.query(query)
            
            print(f"ğŸ¤– Respuesta: {result['response']}")
            
            if result['sources']:
                print("\nğŸ“š Fuentes (top 2):")
                for j, source in enumerate(result['sources'][:2], 1):
                    print(f"  {j}. {source[:120]}...")
            
            print("-" * 60)
        
        print("\nğŸ‰ Demo completada!")
        print("ğŸš€ Para usar la interfaz completa optimizada:")
        print("   streamlit run app.py")
        print("ğŸ’¡ El sistema ahora usa DialoGPT-Large y MPNet-v2 para mejores resultados")
        
    except ImportError as e:
        print(f"âŒ Error de importaciÃ³n: {e}")
        print("AsegÃºrate de haber instalado todas las dependencias:")
        print("conda env create -f environment.yml")
        print("conda activate chatbot_imdb")
    except Exception as e:
        print(f"âŒ Error ejecutando demo: {e}")

if __name__ == "__main__":
    run_demo()
